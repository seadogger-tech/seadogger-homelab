# Replicated metadata pool
apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
  name: ecpool-metadata
  namespace: rook-ceph
spec:
  failureDomain: host
  replicated:
    size: 3
  parameters:
    compression_mode: aggressive
  mirroring: {}
  statusCheck:
    mirror: {}
---
# EC pool configuration
apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
  name: ecpool
  namespace: rook-ceph
spec:
  failureDomain: host
  erasureCoded:
    dataChunks: 2
    codingChunks: 1
  parameters:
    compression_mode: aggressive
    rgw_optimization: "true"
    data_pool: ecpool
    metadata_pool: ecpool-metadata
  deviceClass: nvme  # Changed from hdd to nvme
  mirroring: {}
  statusCheck:
    mirror: {}
---
# StorageClass configuration
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-ceph-ec
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: rook-ceph.rbd.csi.ceph.com
parameters:
  clusterID: rook-ceph
  pool: ecpool
  dataPool: ecpool
  imageFormat: "2"
  imageFeatures: layering
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
  csi.storage.k8s.io/fstype: ext4
allowVolumeExpansion: true
reclaimPolicy: Delete