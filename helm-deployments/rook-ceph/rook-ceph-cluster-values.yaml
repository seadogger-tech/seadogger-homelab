operatorNamespace: rook-ceph

cephClusterSpec:
  cephVersion:
    image: quay.io/ceph/ceph:v19.2.0
    allowUnsupported: false

  dataDirHostPath: /var/lib/rook

  mon:
    count: 3
    allowMultiplePerNode: false
    placement:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - anakin
              - obiwan
              - rey

  dashboard:
    enabled: true
    ssl: false

  network:
    provider: host

  # Disable crash collector to save resources
  crashCollector:
    disable: true

  # Disable monitoring
  monitoring:
    enabled: false

  mgr:
    count: 1
    modules:
    - name: balancer
      enabled: true
    placement:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
              - anakin
              - obiwan
              - rey

resources:
  mgr:
    limits:
      cpu: "1000m"      # 1 core max
      memory: "1Gi"     # Increased for better performance
    requests:
      cpu: "250m"
      memory: "512Mi"   # Increased base allocation

  mon:
    limits:
      cpu: "1000m"      # 1 core max
      memory: "1Gi"     # Increased for stability
    requests:
      cpu: "250m"
      memory: "512Mi"   # Increased base allocation

  osd:
    limits:
      cpu: "2000m"      # 2 cores max - OSDs need more CPU
      memory: "2Gi"     # Increased for better performance
    requests:
      cpu: "500m"
      memory: "1Gi"     # OSDs need more memory

  prepareosd:
    limits:
      cpu: "500m"
      memory: "512Mi"   # Temporary operation, can be higher
    requests:
      cpu: "250m"
      memory: "256Mi"

  mgr-sidecar:
    limits:
      cpu: "500m"
      memory: "512Mi"
    requests:
      cpu: "100m"
      memory: "256Mi"

  storage:
    useAllNodes: false
    useAllDevices: false
    config:
      osdsPerDevice: "1"
      storeType: "bluestore"
      deviceClass: "nvme"
    nodes:
    - name: anakin.local
      devices:
      - name: /dev/nvme0n1p3
        config:
          deviceClass: "nvme"
    - name: obiwan.local
      devices:
      - name: /dev/nvme0n1p3
        config:
          deviceClass: "nvme"
    - name: rey.local
      devices:
      - name: /dev/nvme0n1p3
        config:
          deviceClass: "nvme"

# Explicitly disable CephFS
cephFileSystems: []

# Explicitly disable Object Store
cephObjectStores: []

cephBlockPools:
  - name: ec-pool
    spec:
      failureDomain: host
      erasureCoded:
        dataChunks: 2
        codingChunks: 1
      parameters:
        crushRoot: "default"
    storageClass:
      enabled: true
      name: "rook-ceph-ec-block"
      isDefault: true
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      parameters:
        pool: ec-pool
        thick-provisioning: "false"
        compression_mode: "none"
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
        csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
        imageFeatures: layering

csi:
  enableCephfsDriver: false
  enableRbdDriver: true
  enableCephfsSnapshotter: false
  enableRBDSnapshotter: true
  enableNFSDriver: false
  
  provisionerResources:
    limits:
      cpu: "200m"
      memory: "256Mi"
    requests:
      cpu: "50m"
      memory: "128Mi"
  
  pluginResources:
    limits:
      cpu: "200m"
      memory: "256Mi"
    requests:
      cpu: "50m"
      memory: "128Mi"

# Disable monitoring completely
monitoring:
  enabled: false

dashboard:
  enabled: true
  ssl: false
  ingress:
    enabled: false

toolbox:
  enabled: true
  resources:
    limits:
      cpu: "200m"
      memory: "256Mi"
    requests:
      cpu: "50m"
      memory: "128Mi"