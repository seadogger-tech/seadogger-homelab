#!/bin/bash

set -e

RED="\033[0;31m"
GREEN="\033[0;32m"
YELLOW="\033[1;33m"
NC="\033[0m" # No Color

function info() {
  echo -e "${YELLOW}$1${NC}"
}

function success() {
  echo -e "${GREEN}$1${NC}"
}

function fail() {
  echo -e "${RED}$1${NC}"
}

info "\nğŸ”ª Nuking rook-ceph from your cluster..."

# Step 1: Delete namespace
info "ğŸ§¹ Step 1: Forcibly delete rook-ceph namespace..."
kubectl delete ns rook-ceph --grace-period=0 --force 2>/dev/null || success "âœ… Namespace rook-ceph already deleted"

# Step 2: Delete CRDs
info "ğŸ§¹ Step 2: Delete all rook/ceph CRDs (skip if gone)..."
for crd in $(kubectl get crd | grep -Ei 'rook|ceph' | awk '{print $1}'); do
  echo "  ğŸ”¸ Deleting $crd"
  kubectl delete crd "$crd" --ignore-not-found
done

# Step 3: Clean local disk
info "ğŸ§¹ Step 3: Remove local /var/lib/rook and plugins..."
sudo rm -rf /var/lib/rook
sudo rm -rf /var/lib/kubelet/plugins/rook* || true

# Step 4: Validation
info "ğŸ§ª Step 4: Validating cleanup..."

function check_empty() {
  local desc="$1"
  local cmd="$2"
  if eval "$cmd" | grep -q .; then
    fail "âŒ $desc still present"
    eval "$cmd"
  else
    success "âœ… $desc cleaned"
  fi
}

check_empty "Rook namespace" "kubectl get ns | grep rook"
check_empty "Rook/Ceph CRDs" "kubectl get crd | grep -Ei 'ceph|rook'"
check_empty "Helm releases" "helm list -A | grep rook"
check_empty "PVCs" "kubectl get pvc -A | grep rook"
check_empty "PVs" "kubectl get pv | grep rook"

if [ -d "/var/lib/rook" ]; then
  fail "âŒ /var/lib/rook directory still exists"
else
  success "âœ… /var/lib/rook directory removed"
fi

if ls /var/lib/kubelet/plugins/rook* &>/dev/null; then
  fail "âŒ /var/lib/kubelet/plugins/rook* still exists"
else
  success "âœ… /var/lib/kubelet/plugins/rook* removed"
fi

success "\nğŸ Rook-Ceph nuke complete!"


# Step 5: Validate disk usage on worker nodes
info "ğŸ“¦ Step 5: Validating disks on worker nodes..."

for node in obiwan anakin rey; do
  echo -e "${YELLOW}ğŸ” Checking disk usage on $node...${NC}"
  ssh "pi@${node}.local" 'df -hT / | grep -vE "^Filesystem|tmpfs|udev"' || fail "âŒ SSH to $node.local failed or disk check error"
done
